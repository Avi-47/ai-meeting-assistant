ğŸ§  AI Meeting Assistant

A local AI-powered meeting assistant that listens to your speech, extracts questions, detects intents, and generates instant and refined answers in real-time.

âš ï¸ Note: Currently, only main.py is fully functional. Please use it to run the assistant.

âœ¨ Features

ğŸ¤ Push-to-talk recording with hotkeys (Alt + M to start, Alt + N to stop)

ğŸ—£ï¸ Real-time transcription using Whisper

â“ Question extraction from transcribed audio

ğŸ¯ Intent detection with instant response templates

ğŸ¤– AI-generated answers using a local LLM pipeline

ğŸ–¥ï¸ Overlay UI showing live and final responses

ğŸ“œ Conversation logging to track interactions

ğŸ› ï¸ Requirements

Python 3.10+

Install dependencies:

pip install -r requirements.txt


Optional: Create a .env file for any secret keys (currently not used by main.py)

ğŸš€ Usage

Run the assistant:

python main.py

ğŸ”‘ Hotkeys

Alt + M â†’ Start recording

Alt + N â†’ Stop recording

The overlay will display live transcriptions, instant template answers, and final AI-generated responses.

ğŸ“‚ Project Structure
audio/           # Microphone recording modules
context/         # Question extraction
intent/          # Intent detection and templates
llm/             # AI response generation
logs/            # Conversation logging
stt/             # Speech-to-text modules
triggers/        # Hotkey management
ui/              # Overlay user interface
main.py          # Fully working assistant
main_app.py      # Work in progress
requirements.txt # Python dependencies

âš ï¸ Notes

Keep your secret keys (e.g., Deepgram or Hugging Face tokens) in .env or key.txt â€” do not push them to GitHub.

main_app.py is a work-in-progress and may not run correctly yet.

Contributions and suggestions are welcome!
